{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"<p>goose is a database migration tool. Manage your database schema by creating incremental SQL changes and/or Go functions.</p> <p> Installing goose</p>"},{"location":"#background","title":"Background","text":"<p>github.com/pressly/goose is a fork of bitbucket.org/liamstask/goose with the following changes:</p> <ul> <li>No config files</li> <li>Default <code>goose</code> binary can migrate SQL files only</li> <li>Go migrations:</li> <li>We don't go build Go migrations functions on-the-fly from within the <code>goose</code> binary</li> <li>Instead, we let you create your own custom <code>goose</code> binary, register your Go migration functions     explicitly and run complex migrations with your own *sql.DB connection</li> <li>Go migration functions let you run your code within an SQL transaction, if you use the *sql.Tx     argument</li> <li>The <code>goose</code> pkg is decoupled from the binary:</li> <li><code>goose</code> pkg doesn't register any SQL drivers anymore, thus no driver panic() conflict within     your codebase!</li> <li><code>goose</code> pkg doesn't have any vendor dependencies anymore</li> <li>We use timestamped migrations by default but recommend a hybrid approach of using timestamps in   the development process and sequential versions in production.</li> </ul>"},{"location":"installation/","title":"Installing goose","text":"<p>This project is both a command-line utility (CLI) and a library. This section covers how to install or build <code>goose</code>.</p> <p>You can also install a pre-compiled binary from the GitHub release page. Don't forget to set the executable bit on macOS and Linux.</p>"},{"location":"installation/#macos","title":"macOS","text":""},{"location":"installation/#homebrew","title":"Homebrew","text":"<p>If you're on a Mac, the easiest way to get started is with the Homebrew package manager.</p> <pre><code>brew install goose\n</code></pre> <p>An installation script is available that works on macOS, see  Linux.</p>"},{"location":"installation/#linux","title":"Linux","text":"<p>At the root of the project is an <code>install.sh</code> script to download and install the binary.</p> <pre><code>curl -fsSL \\\n    https://raw.githubusercontent.com/pressly/goose/master/install.sh |\\\n    sh #(1)!\n</code></pre> <ol> <li> <p>Since this script is downloading directly to <code>/usr/local/bin</code>, you may need to <code>sudo sh</code>. You'll     often see an error such as:</p> <p><code>curl: (23) Failure writing output to destination</code></p> <p>Alternatively, change the output to a directory your current user can write to by setting <code>GOOSE_INSTALL</code>.</p> </li> </ol> <p> The default output directory is <code>/usr/local/bin</code>, but can be changed by setting <code>GOOSE_INSTALL</code>. Do not include <code>/bin</code>, it is added by the script.</p> <p> Optionally, a version can be specified as an argument. The default is to download the <code>latest</code> version.</p> <pre><code>curl -fsSL \\\n    https://raw.githubusercontent.com/pressly/goose/master/install.sh |\\\n    GOOSE_INSTALL=$HOME/.goose sh -s v3.5.0\n</code></pre> <p>This will install <code>goose version v3.5.0</code> in directory:</p> <pre><code>$HOME/.goose/bin/goose\n</code></pre>"},{"location":"installation/#windows","title":"Windows","text":"<p>No installation script is available, but you can download a pre-built Windows binary or build from source if Go is installed.</p>"},{"location":"installation/#building-from-source","title":"Building from source","text":"<p>You'll need Go 1.16 or later.</p> <pre><code>go install github.com/pressly/goose/v3/cmd/goose@latest\n</code></pre> <p>Alternatively, you can clone the repository and build from source.</p> <pre><code>git clone https://github.com/pressly/goose\ncd goose\ngo mod tidy\ngo build -o goose ./cmd/goose\n\n./goose --version\n# goose version:(devel)\n</code></pre> <p>This will produce a <code>goose</code> binary ~15M in size because it includes all supported drivers.</p>"},{"location":"installation/#lite-version","title":"Lite version","text":"<p>For a lite version of the binary, use the exclusive build tags. Here's an example where we target only <code>sqlite</code>, and the resulting binary is ~8.7M in size.</p> <pre><code>go build \\\n    -tags='no_postgres no_clickhouse no_mssql no_mysql' \\\n    -o goose ./cmd/goose\n</code></pre> <p>Bonus, let's make this binary smaller by stripping debugging information.</p> <pre><code>go build \\\n    -ldflags=\"-s -w\" \\\n    -tags='no_postgres no_clickhouse no_mssql no_mysql' \\\n    -o goose ./cmd/goose\n</code></pre> <p>We're still only targeting <code>sqlite</code> and reduced the binary to ~6.6M.</p> <p>You can go further with a tool called <code>upx</code>, for more info check out Shrink your go binaries with this one weird trick.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2021/welcome/","title":"Hello, docs!","text":"<p>Introductory blog post. I guess I'll write a few words.</p> <p><code>goose</code> was originally open sourced in late 2012 by Liam Staskawicz on bitbucket.org/liamstask/goose with an MIT license.</p> <p>Great project at the time. Remember, Go itself reached version 1.0 in the same year (March, 2012).</p> <p>However, there were a few items left to be desired, and so the Pressly team forked the project in 2016 and has maintained it since. You can read the Goals of this fork section for more info. But that's enough looking back. Let's look into the future.</p> <p>We aim to continue maintaining <code>goose</code>; adding new features, fixing bugs and providing developer resources to improve the experience. There are also newer features of the standard library and community packages we may consider adopting.</p> <p>There are lots of issues to triage, and a few burning features we need to implement.</p> <p>After thousands of migrations in production we've learned a thing or two, and have ideas on how to improve <code>goose</code> even more. Stay tuned!</p>"},{"location":"blog/2021/embed-sql-migrations/","title":"Embedding migrations","text":""},{"location":"blog/2021/embed-sql-migrations/#embedding-migrations","title":"Embedding migrations","text":"<p>Go continues to be boring while sprinkling quality of life features. One of the recent additions was the ability to embed files at compile time. Click here for go1.16 release notes.</p> <p>Sine many users compile <code>goose</code> themselves, this new embed feature paves the way for embedding SQL files directly into the <code>goose</code> binary. This was already possible with existing tools, however, now that embedding is part of the standard library it's never been easier to offer this feature.</p>"},{"location":"blog/2021/embed-sql-migrations/#but-why","title":"But why?","text":"<p>We'll save \"why would I compile <code>goose</code> myself?\" for another post, instead we'll focus on why embedding files is an improvement to existing workflows.</p> <p>A typical workflow looks something like this:</p> <ol> <li>Developer introduces new SQL migration file</li> <li>File gets merged to <code>main</code> and a <code>goose</code> binary is built</li> <li>The binary along with SQL files is copied into a docker container</li> <li>The docker container is run as a singleton against the database before the application starts up</li> </ol> <p>One of the cumbersome things about this workflow is that the <code>goose</code> binary and the migration files need to be shipped together and the directory structure has to be maintained.</p> <p>But now that <code>goose</code> natively supports embedding files it simplifies the workflow. A <code>goose</code> binary is shipped without any file dependencies, i.e., the migration files are baked into the binary itself.</p>"},{"location":"blog/2021/embed-sql-migrations/#gotchas","title":"Gotchas","text":"<p>We did not implement this in a backwards-compatible way, i.e., the feature is not guarded with build tags. Which means starting with v3.1.0 you must be on go1.16 and up.</p> <p>For older <code>goose</code> versions you may still pin v3.0.1.</p>"},{"location":"blog/2021/embed-sql-migrations/#try-it-out","title":"Try it out!","text":"<p>Remember, the files to be embedded must be relative to the source file(s). Here is what our directory structure might look like:</p> <pre><code>.\n\u251c\u2500\u2500 embed_example.sql\n\u251c\u2500\u2500 go.mod\n\u251c\u2500\u2500 go.sum\n\u2514\u2500\u2500 internal\n    \u2514\u2500\u2500 goose\n        \u251c\u2500\u2500 main.go\n        \u2514\u2500\u2500 migrations\n            \u2514\u2500\u2500 00001_create_users_table.sql\n</code></pre> <p>Here is a fully working example using an in-memory database (SQLite).</p> <pre><code>package main\n\nimport (\n    \"database/sql\"\n    \"embed\"\n    \"log\"\n\n    _ \"github.com/mattn/go-sqlite3\"\n    \"github.com/pressly/goose/v3\"\n)\n\n//go:embed migrations/*.sql\nvar embedMigrations embed.FS // (1)\n\nfunc main() {\n    log.SetFlags(0)\n    db, err := sql.Open(\"sqlite3\", \"embed_example.sql\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    goose.SetDialect(\"sqlite3\")\n    goose.SetBaseFS(embedMigrations) // (2)\n\n    if err := goose.Up(db, \"migrations\"); err != nil { // (3)\n        panic(err)\n    }\n    if err := goose.Version(db, \"migrations\"); err != nil {\n        log.Fatal(err)\n    }\n    rows, err := db.Query(`SELECT * FROM users`)\n    if err != nil {\n        log.Fatal(err)\n    }\n    var user struct {\n        ID       int\n        Username string\n    }\n    for rows.Next() {\n        if err := rows.Scan(&amp;user.ID, &amp;user.Username); err != nil {\n            log.Fatal(err)\n        }\n        log.Println(user.ID, user.Username)\n    }\n}\n</code></pre> <ol> <li> <p>This <code>//go:embed</code> is a special directive that tells the Go tooling to read files from the package    directory or subdirectories at compile time and stores them in the a variable of type    <code>embed.FS</code>.The <code>embed.FS</code> will store a read-only collection of *.sql files.</p> </li> <li> <p>Pass the <code>embed.FS</code> variable to <code>goose</code>. This instructs <code>goose</code> to use the embedded filesystem    instead of opening files from the underlying os.</p> </li> <li> <p>You still have to tell <code>goose</code> which directory contains the .sql files. This implementation    allowed us to keep existing functions without having to change the function signature or add new    functions.It is a drop-in feature that enables the caller to either use the os (as    before) or use embedded filesystem without changing parts of their existing programs.</p> </li> </ol> <p>A sample repo can be found at mfridmn/goose-demo</p> <p>From the root of the directory you can build the binary, and to prove it has no dependencies move it to your home directory and run the binary. This will create a embed_example.sql file for sqlite database. Cool right?!</p> <pre><code>go build -o goosey internal/goose/main.go\nmv goosey $HOME\ncd $HOME\n./goosey\n</code></pre> <p>Output:</p> <pre><code>OK    00001_create.sql\ngoose: no migrations to run. current version: 1\ngoose: version 1\n0 root\n1 goosey\n</code></pre>"},{"location":"blog/2021/better-tests/","title":"Better tests with containers","text":"<p>Managing state is hard. Managing database state is even harder. And coordinating state within a test suite is just always a bad time.</p> <p>But it doesn't have to be this way!</p> <p>There is a fantastic Go package called ory/dockertest that allows you to spin up ephemeral docker containers. It'll work both locally (assuming you have Docker installed) and in your Continuous Integration (CI) pipelines.</p> <p>After applying thousands of migrations in production we know <code>goose</code> is production-ready and does the right thing. But we have plans to add more functionality to <code>goose</code>, and integration tests are a welcome addition to the <code>goose</code> test-suie.</p> <p>In a recent <code>goose</code> release (PR#276) we added container-based database tests. These tests spin up a fresh database per test. Yes, that's right, we're talking dozens of containers.</p> <p>After each test is completed the container is cleaned up, something like this:</p> <pre><code>t.Cleanup(func() {\n    if err := pool.Purge(container); err != nil {\n        log.Printf(\"failed to purge resource: %v\", err)\n    }\n})\n</code></pre> <p>For integration tests this is perfect. We can spin up a fresh lightweight container for each test, such as <code>postgres:14-alpine</code>, and not worry about tests stomping on each other or having to coordinate state between tests.</p> <p>The entire thing is fast! Where tests run in parallel using <code>t.Parallel()</code> and the entire integration test-suite run in about 6-7s (for <code>postgres:14-alpine</code>).</p> <p>Check it out..</p> <pre><code>+--------+---------+----------------------------+---------+\n| STATUS | ELAPSED |            TEST            | PACKAGE |\n+--------+---------+----------------------------+---------+\n| PASS   |    5.77 | TestMigrateOutOfOrderDown  | e2e     |\n| PASS   |    5.54 | TestNowAllowMissingUpByOne | e2e     |\n| PASS   |    5.28 | TestAllowMissingUp         | e2e     |\n| PASS   |    4.60 | TestAllowMissingUpByOne    | e2e     |\n| PASS   |    4.48 | TestNotAllowMissing        | e2e     |\n| PASS   |    4.39 | TestMigrateUpTo            | e2e     |\n| PASS   |    4.31 | TestMigrateUpByOne         | e2e     |\n| PASS   |    3.69 | TestMigrateUp              | e2e     |\n| PASS   |    2.30 | TestMigrateFull            | e2e     |\n+--------+---------+----------------------------+---------+\n\n+--------+---------+---------------------------------------+\n| STATUS | ELAPSED |                PACKAGE                |\n+--------+---------+---------------------------------------+\n| PASS   | 6.12s   | github.com/pressly/goose/v3/tests/e2e |\n+--------+---------+---------------------------------------+\n</code></pre> <p>So, next time you need a database in your containers</p>"},{"location":"blog/2021/out-of-order-migrations/","title":"Adding support for out-of-order migrations","text":"<p>Starting with <code>goose</code> v3.3.0 we added the ability to apply missing (out-of-order) migrations. Thanks for all the the community feedback over the years.</p> <p>Let's back it up, what are \"missing\" or \"out-of-order\" migrations?</p> <p>Suppose migration 1 and 4 are applied and then 2, 3, 5 are introduced. Prior to v3.3.0 <code>goose</code> would ignore migrations 2, 3 and apply only 5. Although this might seem odd, this is fairly consistent behaviour with other migration tools.</p> <p>However, many users were not satisfied with this behaviour, summarized as:</p> <ul> <li>migrations 2 and 3 are \"silently\" ignored</li> <li>unable to apply migrations 2 and 3 if newer versions have already been applied. To paraphrase this   comment:</li> </ul> <p>I would very much prefer just to apply Bill's migration and call it a day.</p> <p>This comment from <code>@zmoazeni</code> has stuck with me over the years.</p> <p>Given that <code>goose</code> maintains a full history of applied migrations in its <code>goose_db_version</code> table, we are able to resolve the database state against the migration files. And now, if missing (out-of-order) migrations are detected users can opt-in to apply them.</p> <p>Internally within Pressly (acquired by Alida) we suggested adopting the hybrid versioning approach. Briefly, in development developers create timestamped migrations, and subsequently when that PR is merged into the <code>main</code> branch its converted into a sequential migration. This is done with the <code>goose fix</code> command.</p> <p>Then when a release is cut and rolled out to production only sequential migrations are applied. It was a solution to the problem that worked for our team. Yes, yes.. this does require developers to be rebasing/merging and resolving conflicts (if any) between migrations.</p> <p></p> <ul> <li>A timestamped version uses a time-based format (second resolution): <code>20060102150405</code></li> <li>A sequential version is typically a low number</li> </ul> <p>There should never (at least in our lifetime) be a collision between timestamped and sequential versions.</p> <p>Buttttt..... as we listened to community feedback, and saw the rise in the number of <code>goose</code> forks (mainly to support missing migrations), we decided the community was right. The hybrid versioning approach is not for everyone and it wasn't fair for us to impose this strict restriction.</p> <p>I think this comment summarized it well:</p> <p>We should meet users in the middle (lots of great feedback from the community) and give them the flexibility to use <code>goose</code> as they see fit. The responsibility will be shifted from the tool itself, to the end user.</p> <p>To recap, this is the new behaviour of <code>goose</code>:</p> <p>If you attempt to apply missing (out-of-order) migrations <code>goose</code> will raise an error (previously <code>goose</code> would ignore these migrations). However, if you do want to apply these missing migrations pass <code>goose</code> the <code>-allow-missing</code> flag, or if using as a library supply the functional option <code>goose.WithAllowMissing()</code> to Up, UpTo or UpByOne commands.</p> <p>More details can be found in the Changelog and the issue #262.</p> <p>Hope folks find this useful. More awesome things are planned for <code>goose</code> \ud83d\ude80.</p> <p>ps. consider dropping pressly/goose a \u2b50\ufe0f if you find this package useful.</p>"},{"location":"blog/2021/no-version-migrations/","title":"Ad-hoc migrations with no versioning","text":"<p>This post describes a new feature recently added to <code>goose</code> -- the ability to apply migrations with no versioning. A common use case is to seed a database with data after versioned migrations have been applied.</p> <p>If you think of versioned migrations as the blueprint for a house (the schema), then unversioned migrations are like the furnishings inside (the data).</p> <p>A GitHub user @soggycactus stated the problem well (#235 comment):</p> <p>... I always find myself creating some sort of wrapper that allows me to use goose to seed my local and development environments with test data</p>"},{"location":"blog/2021/no-version-migrations/#brief-summary","title":"Brief Summary","text":"<ul> <li>keep versioned migrations in a dedicated directory (e.g., ./schema/migrations)</li> <li>continue running <code>goose</code> commands like normal: <code>goose -dir ./schema/migrations up</code></li> <li>add unversioned migrations to a different directory (e.g., ./schema/seed)</li> <li>run <code>goose</code> commands with <code>-no-versioning</code> flag using seed directory</li> </ul> <p>By adding <code>-no-versioning</code> flag (CLI) or supplying <code>WithNoVersioning()</code> option (library), we instruct <code>goose</code> to apply migrations but to ignore tracking the version in the database schema table.</p>"},{"location":"blog/2021/no-version-migrations/#but-why","title":"But why?","text":"<p>A common use case is to seed an environment with data, such as local development environment or integration tests. Because we don't want this data to be applied to production, we keep it separate from the versioned migrations in a different directory.</p> <p>Seed data: think many <code>INSERT INTO</code> statements in up migrations and <code>DELETE FROM</code> or <code>TRUNCATE</code> in down migrations.</p> <ul> <li>new developer joins, spins up a database, applies versioned migrations but requires \"seed\" data to   get started</li> <li>integration or end-end tests that rely on pre-existing data. It's common to have your application   create data, but sometimes you just want data to be there for external tests not involving your   API</li> <li>optimizing delicate queries on a database with pre-populated data. Avoid writing queries against   an empty database</li> </ul> <p>Remember, if your application does requires some static, pre-existing data, then just insert it along with your regular versioned schema migrations.</p>"},{"location":"blog/2021/no-version-migrations/#example","title":"Example","text":"<p>Seeding integration tests and wiping data, without having to reset the database schema.</p> <p>Let's use an example:</p> <pre><code>.\n\u2514\u2500\u2500 schema\n    \u251c\u2500\u2500 migrations\n    \u2502   \u251c\u2500\u2500 00001_add_users_table.sql\n    \u2502   \u251c\u2500\u2500 00002_add_posts_table.sql\n    \u2502   \u2514\u2500\u2500 00003_alter_users_table.sql\n    \u2514\u2500\u2500 seed\n        \u251c\u2500\u2500 00001_seed_users_table.sql\n        \u2514\u2500\u2500 00002_seed_posts_table.sql\n</code></pre> <p>Running the following command creates the desired shape of the database:</p> <pre><code>goose -dir ./schema/migrations up\n</code></pre> <p>Assuming you're using the default goose table name <code>goose_db_version</code> then querying this table will return 3 versioned migrations.</p> <p>Now, suppose we want to run integration tests against a database that contains pre-populated data. Running the following command applies two migrations but it does not track their version in the database.</p> <pre><code>goose -dir ./schema/seed -no-versioning up\n</code></pre> <p>If you run the initial command again:</p> <pre><code>goose -dir ./schema/migrations up\n</code></pre> <p><code>goose</code> will output \"no new migrations found\". Because <code>goose</code> knows we already applied 3 migrations, so no further work to do.</p> <p>But, if you run the second command again:</p> <pre><code>goose -dir ./schema/seed -no-versioning up\n</code></pre> <p><code>goose</code> doesn't know about unversioned migrations (due to the <code>-no-versioning</code> flag) so it will apply the seed migrations once again. Depending how you wrote the migrations, this may or may not succeed.</p> <p>Lastly, we're done with our integration test. The neat thing with the <code>-no-versioning</code> flag is it enables you to wipe the data without having to migrate the entire database down and up again.</p> <p>Running the following command will apply the down migrations in your seed files, in reverse order:</p> <pre><code>goose -dir ./schema/seed -no-versioning down-to 0\n# or\ngoose -dir ./schema/seed -no-versioning reset\n</code></pre> <p>These two commands are the same--applying all down migrations starting from the highest to the lowest numbered migration files in the schema directory.</p>"},{"location":"blog/2021/no-version-migrations/#final-thoughts","title":"Final Thoughts","text":"<p>With the <code>-no-versioning</code> flag (CLI) or <code>WithNoVersioning()</code> option (library) you now have the ability to apply arbitrary SQL statements to the database.</p> <p>Just remember, these operations are not tracked (versioned) and are intended to be used in development/testing environments.</p>"},{"location":"blog/2021/visualizing-up-down-commands/","title":"A tour of goose up and down commands","text":"<p>A while ago a co-op student, who happened to be a visual leaner, asked if it were possible to explain <code>goose</code> commands visually. At the time we were still at an office, so we gathered around the whiteboard and doodled some diagrams.</p> <p>This post captures some of those whiteboard sketches, which seemed to help.</p>"},{"location":"blog/2021/visualizing-up-down-commands/#up-commands","title":"up commands","text":"<code>goose up</code> <p>migrate all pending migrations to the most recent version</p> <code>goose up-by-one</code> <p>migrate a single pending version</p> <code>goose up-to N</code> <p>migrate to a specific pending version, where N is a migration number</p>"},{"location":"blog/2021/visualizing-up-down-commands/#up-examples","title":"up examples","text":"<p>Let's illustrate up commands with a concrete example.</p> <p>Suppose our ./schema/migrations folder contains 11 migration files. We have previously applied 8 migrations and 3 migrations are currently pending.</p> <p>Running <code>goose version</code> returns: goose: version 8</p> <p>Running <code>goose status</code> returns:</p> <pre><code>Applied At                  Migration\n=======================================\nSun Dec 19 20:09:48 2021 -- 00001_a.sql\nSun Dec 19 20:09:48 2021 -- 00002_b.sql\nSun Dec 19 20:09:48 2021 -- 00003_c.sql\nSun Dec 19 20:09:48 2021 -- 00004_d.sql\nSun Dec 19 20:09:48 2021 -- 00005_e.sql\nSun Dec 19 20:09:48 2021 -- 00006_f.sql\nSun Dec 19 20:09:48 2021 -- 00007_g.sql\nSun Dec 19 20:09:48 2021 -- 00008_h.sql\nPending                  -- 00009_i.sql\nPending                  -- 00010_j.sql\nPending                  -- 00011_k.sql\n</code></pre> <ul> <li>Running <code>goose up</code> applies all 3 pending migrations: 9, 10 and 11</li> <li>Running <code>goose up-by-one</code> applies only migration 9</li> <li>Running <code>goose up-to 8</code> does nothing, since 8 has already been applied</li> <li>Running <code>goose up-to 10</code> applies migrations 9 and 10</li> </ul> <p></p>"},{"location":"blog/2021/visualizing-up-down-commands/#down-commands","title":"down commands","text":"<code>goose down</code> <p>migrate the latest version down</p> <code>goose down-to N</code> <p>migrate down to a specific version, where N is a migration number</p>"},{"location":"blog/2021/visualizing-up-down-commands/#down-examples","title":"down examples","text":"<p>Let's illustrate down commands, continuing with the above example. We have previously applied all 11 migrations from the ./schema/migrations folder.</p> <p>Running <code>goose version</code> returns: goose: version 11</p> <p>Running <code>goose status</code> returns:</p> <pre><code>Applied At                  Migration\n=======================================\nSun Dec 19 21:31:11 2021 -- 00001_a.sql\nSun Dec 19 21:31:11 2021 -- 00002_b.sql\nSun Dec 19 21:31:11 2021 -- 00003_c.sql\nSun Dec 19 21:31:11 2021 -- 00004_d.sql\nSun Dec 19 21:31:11 2021 -- 00005_e.sql\nSun Dec 19 21:31:11 2021 -- 00006_f.sql\nSun Dec 19 21:31:11 2021 -- 00007_g.sql\nSun Dec 19 21:31:11 2021 -- 00008_h.sql\nSun Dec 19 21:31:11 2021 -- 00009_i.sql\nSun Dec 19 21:31:11 2021 -- 00010_j.sql\nSun Dec 19 21:31:11 2021 -- 00011_k.sql\n</code></pre> <ul> <li>Running <code>goose down</code> applies the down migration for 11</li> <li>Running <code>goose down-to 11</code> does nothing</li> <li>Running <code>goose down-to 9</code> applies the down migrations for 11 and 10</li> <li>Running <code>goose down-to 0</code> applies all down migrations</li> </ul> <p></p> <p>Bonus</p> <p><code>goose down-to 0</code> is the same as <code>goose reset</code>. Applying all down migrations.</p> <p><code>goose redo</code> is the same as <code>goose down</code> followed by <code>goose up-by-one</code>. Reapplying the latest migration.</p>"},{"location":"blog/2022/improving-clickhouse/","title":"Improving ClickHouse support","text":"<p>ClickHouse is a an open-source column-oriented database that is well-suited for analytical workloads. Over the past few years we've seen more and more demand for improved ClickHouse support in goose.</p> <p>To summarize:</p> <ul> <li>Upgraded to the latest <code>/v2</code> driver:   ClickHouse/clickhouse-go</li> <li>Full end-end tests against the docker image:   clickhouse/clickhouse-server</li> <li>Bug fixes and improvements</li> </ul> <p>The <code>/v2</code> driver changed the DSN format, so be prepared for a breaking change. This is actually a good thing, because it brings the format in-line with other databases.</p>"},{"location":"blog/2022/improving-clickhouse/#getting-started","title":"Getting started","text":"<p>Here's a quick tour of using goose against a running ClickHouse docker container.</p> <pre><code>docker run --rm -d \\\n    -e CLICKHOUSE_DB=clickdb \\\n    -e CLICKHOUSE_USER=clickuser \\\n    -e CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1 \\\n    -e CLICKHOUSE_PASSWORD=password1 \\\n    -p 9000:9000/tcp clickhouse/clickhouse-server:22-alpine\n</code></pre> <p>Once the container is running, we'll apply 3 migrations with goose. For the sake of this demo, we're using migrations from pressly/goose repository.</p> <p>At the time of this writing, goose supports 3 environment variables:</p> <pre><code>GOOSE_DRIVER\nGOOSE_DBSTRING\nGOOSE_MIGRATION_DIR\n</code></pre> <p>We use them in the following command for convenience. Otherwise you'll need to set the driver and database connection strings as CLI parameters and the migration directory with the <code>-dir</code> flag.</p> <pre><code>GOOSE_DRIVER=clickhouse \\\n    GOOSE_DBSTRING=\"tcp://clickuser:password1@localhost:9000/clickdb\" \\\n    GOOSE_MIGRATION_DIR=\"tests/clickhouse/testdata/migrations\" \\\n    goose up\n</code></pre> <p>Expected output following a successful migration.</p> <pre><code>2022/06/19 20:19:04 OK    00001_a.sql\n2022/06/19 20:19:04 OK    00002_b.sql\n2022/06/19 20:19:04 OK    00003_c.sql\n2022/06/19 20:19:04 goose: no migrations to run. current version: 3\n</code></pre>"},{"location":"blog/2022/improving-clickhouse/#check-migrations","title":"Check migrations","text":"<p>We can now use the <code>clickhouse-client</code> to poke around the server:</p>"},{"location":"blog/2022/improving-clickhouse/#show-tables","title":"Show tables","text":"<pre><code>clickhouse-client --vertical \\\n    --database clickdb --password password1 -u clickuser \\\n    -q 'SHOW TABLES'\n</code></pre> <p>Our migrations created the <code>goose_db_version</code> table, which stores migration data, and 2 new user tables: <code>clickstream</code> and <code>trips</code>.</p> <pre><code>Row 1:\n\u2500\u2500\u2500\u2500\u2500\u2500\nname: clickstream\n\nRow 2:\n\u2500\u2500\u2500\u2500\u2500\u2500\nname: goose_db_version\n\nRow 3:\n\u2500\u2500\u2500\u2500\u2500\u2500\nname: trips\n</code></pre>"},{"location":"blog/2022/improving-clickhouse/#show-all-data-from-clickstream-table","title":"Show all data from <code>clickstream</code> table","text":"<p>We used the sample data from the Getting Started with ClickHouse tutorial.</p> <pre><code>clickhouse-client --vertical \\\n    --database clickdb --password password1 -u clickuser \\\n    -q 'SELECT * FROM clickstream'\n</code></pre> <p>Output:</p> <pre><code>Row 1:\n\u2500\u2500\u2500\u2500\u2500\u2500\ncustomer_id:      customer3\ntime_stamp:       2021-11-07\nclick_event_type: checkout\ncountry_code:\nsource_id:        307493\n\nRow 2:\n\u2500\u2500\u2500\u2500\u2500\u2500\ncustomer_id:      customer2\ntime_stamp:       2021-10-30\nclick_event_type: remove_from_cart\ncountry_code:\nsource_id:        0\n\nRow 3:\n\u2500\u2500\u2500\u2500\u2500\u2500\ncustomer_id:      customer1\ntime_stamp:       2021-10-02\nclick_event_type: add_to_cart\ncountry_code:     US\nsource_id:        568239\n</code></pre>"},{"location":"blog/2022/overview-sql-file/","title":"SQL migration files and goose annotations","text":"<p>In this post we'll explore SQL migration files and <code>+goose</code> annotation comments, which are used to parse SQL statements and optionally modify how migrations are executed.</p> <p>As of this writing there are five annotations:</p> <pre><code>-- +goose Up\n-- +goose Down\n-- +goose StatementBegin\n-- +goose StatementEnd\n-- +goose NO TRANSACTION\n</code></pre> <p>bonus</p> <p>In addition to SQL migration files, the <code>goose</code> package can be used to write Go-based migrations and track both SQL and Go migrations in the same way.</p> <p>See repository example for Go migrations. We'll do a deep dive in a future post. Stay tuned!</p>"},{"location":"blog/2022/overview-sql-file/#quick-start","title":"Quick start","text":"<p>Here's a copy/pasteable <code>.sql</code> migration file to get started:</p> <pre><code>-- +goose Up\nSELECT 'up SQL query';\n\n-- +goose Down\nSELECT 'down SQL query';\n</code></pre> <p>Remember, annotations are captured as comments and cannot have leading spaces:</p> <pre><code>-- +goose Up \u2705\n    -- +goose Up \u274c (error because leading whitespace)\n</code></pre>"},{"location":"blog/2022/overview-sql-file/#the-basics","title":"The basics","text":"<p>A SQL migration file must have a <code>.sql</code> extension and is prefixed with either a timestamp or a sequential number.</p> <p>There is a handy <code>goose create</code> command to stub out migration files in a consistent way:</p>"},{"location":"blog/2022/overview-sql-file/#timestamp","title":"timestamp","text":"<pre><code>$ goose -dir migrations create add_users_table sql\nCreated new file: migrations/20230201093158_add_users_table.sql\n</code></pre>"},{"location":"blog/2022/overview-sql-file/#sequential","title":"sequential","text":"<pre><code>$ goose -dir migrations -s create add_users_table sql # (1)! Created new file:\nmigrations/00001_add_users_table.sql\n</code></pre> <ol> <li>The <code>-s</code> flag instructs goose to create new migration files in sequential order. Timestamp     is the default.</li> </ol> <p>A SQL migration file can have both Up and Down migrations. For the curious, there is an open issue ( #374) requesting support for migrations to be split in separate files.</p> <p>Each SQL migration file is expected to have exactly one <code>-- +goose Up</code> annotation.</p> <p>The <code>-- +goose Down</code> annotation is optional, but recommended, and must come after the Up annotation within the file. Example:</p> <pre><code>-- +goose Up\nSELECT 'up SQL query 1';\nSELECT 'up SQL query 2';\nSELECT 'up SQL query 3';\n\n-- +goose Down (1)\nSELECT 'down SQL query 1';\nSELECT 'down SQL query 2';\n</code></pre> <ol> <li> <p>The <code>-- +goose Down</code> annotation is optional, and may be omitted entirely if there are no down     migrations. Within the <code>.sql</code> file it must come after the <code>-- +goose Up</code> annotation.</p> <p>This is invalid:</p> <pre><code>-- +goose Down\nSELECT 'down SQL query';\n\n-- +goose Up\nSELECT 'up SQL query';\n</code></pre> </li> </ol> <p>Any statements following <code>-- +goose Up</code> will be executed as part of an up migration, and any statements following <code>-- +goose Down</code> will be executed as part of a down migration.</p>"},{"location":"blog/2022/overview-sql-file/#complex-statements","title":"Complex statements","text":"<p>By default, SQL statements are delimited by semicolons - in fact, query statements must end with a semicolon to be properly recognized by <code>goose</code>.</p> <p>More complex statements (PL/pgSQL) that have semicolons within them must be annotated with <code>-- +goose StatementBegin</code> and <code>-- +goose StatementEnd</code> to be properly parsed. For example:</p> <pre><code>-- +goose Up\n\n-- +goose StatementBegin\nCREATE OR REPLACE FUNCTION histories_partition_creation( DATE, DATE )\nreturns void AS $$\nDECLARE\n  create_query text;\nBEGIN\n-- This comment will be preserved.\n  -- And so will this one.\n  FOR create_query IN SELECT\n      'CREATE TABLE IF NOT EXISTS histories_'\n      || TO_CHAR( d, 'YYYY_MM' )\n      || ' ( CHECK( created_at &gt;= timestamp '''\n      || TO_CHAR( d, 'YYYY-MM-DD 00:00:00' )\n      || ''' AND created_at &lt; timestamp '''\n      || TO_CHAR( d + INTERVAL '1 month', 'YYYY-MM-DD 00:00:00' )\n      || ''' ) ) inherits ( histories );'\n    FROM generate_series( $1, $2, '1 month' ) AS d\n  LOOP\n    EXECUTE create_query;\n  END LOOP;  -- LOOP END\nEND;         -- FUNCTION END\n$$\nlanguage plpgsql;\n-- +goose StatementEnd\n</code></pre> <p>When <code>goose</code> detects a <code>-- +goose StatementBegin</code> annotation it continues parsing statement(s), ignoring semicolons, until <code>-- +goose StatementEnd</code> is detected. The resulting statement is stripped of leading and trailing comments / empty lines.</p> <p>Comments and empty lines within the statement are preserved!</p>"},{"location":"blog/2022/overview-sql-file/#multiple-statements","title":"Multiple statements","text":"<p>But that's not all, the Begin and End annotations can be used to combine multiple statements so they get sent as a single command instead of being sent one-by-one.</p> <p>This is best illustrated with a contrived example. Suppose we have a migration that creates a <code>users</code> table and adds 100,000 rows with distinct <code>INSERT</code>'s.</p> <pre><code>-- +goose Up\nCREATE TABLE users (\n    id int NOT NULL PRIMARY KEY,\n    username text,\n    name text,\n    surname text\n);\n\n-- (1)! Inserts:\nINSERT INTO \"users\" (\"id\", \"username\", \"name\", \"surname\") VALUES (1, 'gallant_almeida7', 'Gallant', 'Almeida7');\nINSERT INTO \"users\" (\"id\", \"username\", \"name\", \"surname\") VALUES (2, 'brave_spence8', 'Brave', 'Spence8');\n.\n.\nINSERT INTO \"users\" (\"id\", \"username\", \"name\", \"surname\") VALUES (99999, 'jovial_chaum1', 'Jovial', 'Chaum1');\nINSERT INTO \"users\" (\"id\", \"username\", \"name\", \"surname\") VALUES (100000, 'goofy_ptolemy0', 'Goofy', 'Ptolemy0');\n\n-- +goose Down\nDROP TABLE users;\n</code></pre> <ol> <li> <p>This is a contrived example. Normally this would be a set of batched <code>INSERT</code>'s with multiple     column values, each enclosed with parentheses and separated by commas, like so:</p> <pre><code>INSERT INTO \"users\" (\"id\", \"username\", \"name\", \"surname\")\nVALUES\n  (1, 'gallant_almeida7', 'Gallant', 'Almeida7'),\n  (2, 'brave_spence8', 'Brave', 'Spence8');\n</code></pre> </li> </ol> <p>The Up migration contains 100,001 unique statements, all executed within the same transaction, but sent to the database one-by-one. This migration will take ~38s to complete due to the number of round trips.</p> <p>Using PostgreSQL as an example, here's what the database logs show:</p> <pre><code>LOG:  statement: INSERT INTO \"users\" (\"id\", \"username\", \"name\", \"surname\") VALUES (1, 'gallant_almeida7', 'Gallant', 'Almeida7');\nLOG:  statement: INSERT INTO \"users\" (\"id\", \"username\", \"name\", \"surname\") VALUES (2, 'brave_spence8', 'Brave', 'Spence8');\nLOG:  statement: INSERT INTO \"users\" (\"id\", \"username\", \"name\", \"surname\") VALUES (3, 'lucid_bardeen6', 'Lucid', 'Bardeen6');\n[...] 100,000 log statements\n</code></pre> <p>However, if we want to combine the inserts into a single command, we can wrap them with <code>-- +goose StatementBegin</code> and <code>-- +goose StatementEnd</code> annotations. Note, a single command still contains several statements separated by semicolons, but they get sent to the server in the same query string like so: <code>\"INSERT INTO ...; INSERT INTO ...;\"</code>.</p> <pre><code>-- +goose Up\nCREATE TABLE users (\n    id int NOT NULL PRIMARY KEY,\n    username text,\n    name text,\n    surname text\n);\n\n-- +goose StatementBegin\nINSERT INTO \"users\" (\"id\", \"username\", \"name\", \"surname\") VALUES (1, 'gallant_almeida7', 'Gallant', 'Almeida7');\nINSERT INTO \"users\" (\"id\", \"username\", \"name\", \"surname\") VALUES (2, 'brave_spence8', 'Brave', 'Spence8');\n.\n.\nINSERT INTO \"users\" (\"id\", \"username\", \"name\", \"surname\") VALUES (99999, 'jovial_chaum1', 'Jovial', 'Chaum1');\nINSERT INTO \"users\" (\"id\", \"username\", \"name\", \"surname\") VALUES (100000, 'goofy_ptolemy0', 'Goofy', 'Ptolemy0');\n-- +goose StatementEnd\n\n-- +goose Down\nDROP TABLE users;\n</code></pre> <p>These annotations instruct <code>goose</code> to send a single command, which now consists of multiples statements delimited by semicolons, in one shot.</p> <p>Yes, that's a larger payload, but that's fine and the migration will execute in ~3s, which is an order of magnitude faster as compared to the previous example that ran in ~38s.</p>"},{"location":"blog/2022/overview-sql-file/#migrations-outside-transaction","title":"Migrations outside transaction","text":"<p>All statements within a migration file are run within a transaction. Some statements, like <code>CREATE DATABASE</code> or <code>CREATE INDEX CONCURRENTLY</code>, cannot be run within a transaction block.</p> <p>For such cases add the <code>-- +goose NO TRANSACTION</code> annotation, usually placed at the top of the file.</p> <p>This annotation instructs <code>goose</code> to run all statements within the file without transactions. This applies to all Up and Down statements within the file.</p> <pre><code>-- +goose NO TRANSACTION\n\n-- +goose Up\nCREATE INDEX CONCURRENTLY ON users (user_id);\n\n-- +goose Down\nDROP INDEX IF EXISTS users_user_id_idx;\n</code></pre>"},{"location":"blog/2023/goose-provider/","title":"Adding a goose provider","text":""},{"location":"blog/2023/goose-provider/#introduction","title":"Introduction","text":"<p>In this post, we'll explore the new <code>Provider</code> feature recently added to the core goose package. If you're new to goose, it's a tool for handling database migrations, available as a standalone CLI tool and a package that can be used in Go applications.</p> <p>Requires version v3.16.0 and above.</p> <p>Adding a provider to your application is easy, here's a quick example:</p> <pre><code>provider, err := goose.NewProvider(\n  goose.DialectPostgres, // (1)!\n  db, // (2)!\n  os.DirFS(\"migrations\"), // (3)!\n)\n\nresults, err := provider.Up(ctx) // (4)!\n</code></pre> <ol> <li> <p>The first argument is the dialect. It is the type of database technology you're using. In this     case, we're using Postgres. But goose also supports:</p> <p>clickhouse, mssql, mysql, postgres, redshift, sqlite3, tidb, vertica, ydb,</p> </li> <li> <p>The second argument is the database connection. You can use any database driver you want, as     long as it implements the <code>database/sql</code> interface.</p> <p>A popular choice for Postgres is pgx/v5</p> </li> <li> <p>The last argument may be <code>nil</code>. Why? Because goose also supports the ability to register Go     functions as migrations.</p> <p>However, in most cases, you'll be using SQL migrations and reading them from disk. In this case, you'll use os.DirFS or embed them into your binary and use embed.FS.</p> </li> <li> <p>The last step is to invoke one of the migration methods. In this case, we're running the <code>Up</code>     method, which will run all the migrations that haven't been run yet. Here's a list of all the     methods:</p> <pre><code>  (p *Provider) ApplyVersion\n  (p *Provider) Close\n  (p *Provider) Down\n  (p *Provider) DownTo\n  (p *Provider) GetDBVersion\n  (p *Provider) ListSources\n  (p *Provider) Ping\n  (p *Provider) Status\n  (p *Provider) Up\n  (p *Provider) UpByOne\n  (p *Provider) UpTo\n</code></pre> </li> </ol> <p>All functionality is scoped to the <code>Provider</code> instance. This means that you can create multiple of them, each with their own configuration.</p> <p>Here's some options you can pass to the <code>NewProvider</code> method:</p> Option Description WithGoMigrations Register Go functions as migrations directly within the provider WithSessionLocker Lock database to prevent concurrent migrations WithStore Bring your own store implementation WithExclude Exclude migrations by name or version WithAllowOutofOrder Allow migrations to be run out of order WithDisableVersioning Disable versioning, useful for testing and seeding data <p>... and more!</p>"},{"location":"blog/2023/goose-provider/#backwards-compatibility","title":"Backwards compatibility","text":"<p>Although we're adding a new feature, we're not removing any existing functionality in the /v3 package and the <code>Provider</code> is fully backwards compatible. This means that you can continue to use goose as you always have and migrate at your own pace. Do note, however, that the <code>Provider</code> will be the recommended way to use goose and we'll be focusing our efforts on it going forward.</p> <p>For all the limitations mentioned below, the goose package was (and still is) a great tool and we're grateful for all the contributions and feedback from the community. We hope that the <code>Provider</code> will compliment the existing functionality and make goose even better.</p>"},{"location":"blog/2023/goose-provider/#motivation","title":"Motivation","text":"<p>The motivation behind the <code>Provider</code> was simple - to reduce global state and make goose easier to consume as an imported package.</p> <p>Here's a quick summary:</p> <ul> <li>Avoid global state</li> <li>Make <code>Provider</code> safe to use concurrently</li> <li>Unlock (no pun intended) new features, such as database locking</li> <li>Make logging configurable</li> <li>Better error handling with proper return values</li> <li>Double down on Go migrations</li> </ul>"},{"location":"blog/2023/goose-provider/#global-state","title":"Global state","text":"<p>Some of the functionality mentioned above was not possible, or if it was, would lead to an awkward API. The reason is because goose used global state to store the configuration. This meant that you could only have one configuration at a time, which was fine for the CLI, but not ideal as a package.</p> <p>As an aside, if you're interested in the topic, Peter Bourgon had a nice post about global state</p> <p>tl;dr: magic is bad; global state is magic \u2192 no package level vars; no func init</p> <p>As time went on, goose became more popular and people started using it in more complex ways. For example, they wanted to run parallel tests or run migrations against multiple databases. This made the package unsafe to use, because global state would be overwritten by concurrent calls.</p> <p>By using the <code>Provider</code>, we can scope all functionality to the instance and make it safe to use concurrently. This means that you can create multiple providers, each with their own configuration.</p>"},{"location":"blog/2023/goose-provider/#database-locking","title":"Database locking","text":"<p>Another limitation is all commands, such as <code>goose.Up</code> and <code>goose.Down</code>, would take <code>*sql.DB</code> as the database connection. This made it challenging to implement more advanced features, such as database locking.</p> <p>We'll save the details for another post, but the gist is that for most databases you need to use a <code>*sql.Conn</code> to lock the database, and, most importantly, use the same connection to unlock it.</p> <p>Some users got clever and worked around this limitation by using a wrapper that handled locking or even more  exotic solutions, such as setting the max number of connections to 1.</p> <p>But this was not ideal.</p> <p>With the <code>Provider</code>, you can now pass in a <code>SessionLocker</code> option which can be used to lock the database. The only implementation supported right now is for Postgres, but we plan to add support for other databases as requested. Here's a quick example:</p> <pre><code>sessionLocker, err := lock.NewPostgresSessionLocker(\n  // Timeout after 30min. Try every 15s up to 120 times.\n    lock.WithLockTimeout(15, 120),\n)\n\nprovider, err := goose.NewProvider(\n    goose.DialectPostgres,\n    db,\n    os.DirFS(\"migrations\"),\n    goose.WithSessionLocker(sessionLocker), // Use session-level advisory lock.\n)\n</code></pre> <p>Kudos to @roblaszczak for the idea to support a custom locker interface.</p> <p>If you've been following  Add locking mechanism to prevent parallel execution issue, there's a bit to unpack. We'll save the details for another post.</p>"},{"location":"blog/2023/goose-provider/#logging","title":"Logging","text":"<p>There was too much logging from within the package. This made it difficult to integrate goose into existing applications, because it would pollute the logs. We still want to have some logging, but we want to make it configurable.</p>"},{"location":"blog/2023/goose-provider/#error-handling-and-return-values","title":"Error handling and return values","text":"<p>This is a big one. There was no way to get the results of a migration because all success and failure states were logged from within the package.</p> <p>With the provider, all methods return a well-defined type, which includes the results of the migration and any errors that occurred. For example, here's the <code>Up</code> method:</p> <pre><code>func (p *Provider) Up(ctx context.Context) ([]*MigrationResult, error) {\n</code></pre> <p>Notice that it returns a slice of <code>*MigrationResult</code> and an error.</p> <p>By having a well-defined return value, we can also improve the CLI output and control the formatting of the results (such as adding JSON support), as opposed to logging them directly in the goose package through the <code>Logger</code>.</p> <p>Lastly, we can handle errors in a more graceful way. Due to the nature of migrations, it's possible that a migration may fail part way through, and we want to know exactly what state we're in. What was the last migration that was run? What was the error? What was the migration that failed?</p> <p>This is now possible because all provider methods return a <code>PartialError</code>.</p>"},{"location":"blog/2023/goose-provider/#go-migrations","title":"Go migrations","text":"<p>Previously, all Go migrations had to be registered globally. This meant that you could only have one set of Go migrations per application.</p> <p>Now, you can register Go migrations directly with the provider, which means you can have multiple providers, each with their own set of Go migrations. Here's a quick example:</p> <pre><code>register := []*goose.Migration{\n    goose.NewGoMigration(\n        1,\n        &amp;goose.GoFunc{RunTx: newTxFn(\"CREATE TABLE users (id INTEGER)\")},\n        &amp;goose.GoFunc{RunTx: newTxFn(\"DROP TABLE users\")},\n    ),\n}\nprovider, err := goose.NewProvider(goose.DialectSQLite3, db, nil,\n    goose.WithGoMigrations(register...),\n)\n</code></pre> <p>The goose provider will automatically register Go migrations and return any conflicts that may occur. This means that you can mix and match SQL and Go migrations, as long as they don't conflict with each other by having the same version.</p>"},{"location":"blog/2023/goose-provider/#conclusion","title":"Conclusion","text":"<p>The <code>Provider</code> is a solid foundation that we can build upon and add new features. We're excited to see how people will use it and what new ideas they'll come up with</p> <p>If you have any questions or feedback, feel free to reach out on Twitter @_mfridman or file an issue on  pressly/goose.</p> <p>ps. It's also an example of how to use functional options in Go, despite their controversial nature. I personally like them, but I can see why some people don't. Here's a great talk by @jub0bs on the topic:</p> <p></p>"},{"location":"blog/2023/goose-provider/#acknowledgments","title":"Acknowledgments","text":"<p>This feature would not have been possible without all the contributions from the community. A special thanks to everyone who opened an issue, submitted a PR, or helped with the design.</p> <p>Special thanks to @oliverpool for pitching ideas and working through the design around the <code>fs.FS</code> interface. I'm quite happy with how it turned out and I think it's a great example of how to use the new <code>fs.FS</code> interface.</p>"},{"location":"blog/2024/goose-sqlc/","title":"Using <code>sqlc</code> and <code>goose</code>","text":"<p>In this post, we give you a brief introduction to <code>sqlc</code> and show you how to use it with <code>goose</code>.</p> <p>For those unfamiliar, sqlc is a SQL compiler that generates Go code from your SQL queries, and goose is a database migration tool for managing your database schema's evolution.</p> <p>Together, these tools can be quite powerful. They allow you to create SQL queries in a type-safe manner and consistently manage your database schema's evolution in a repeatable way.</p>"},{"location":"blog/2024/goose-sqlc/#overview","title":"Overview","text":"<p>A common question is, \"What is the relationship between <code>sqlc</code> and <code>goose</code>?\"</p> <p>To answer this, let's take a step back and briefly outline what <code>sqlc</code> does:</p> <ol> <li>Parses SQL statements</li> <li>Analyzes the SQL statements</li> <li>Generates type-safe Go code for applications to use those statements</li> </ol> <p>In the second step, <code>sqlc</code> requires the database schema to generate the type-safe Go code. This can be accomplished by either pointing <code>sqlc</code> at a database or supplying the schema files.</p> <p>Importantly, the schema files are the same ones you create to establish the database schema and apply with <code>goose</code>.</p> <p></p> <p>For a comprehensive overview of how <code>sqlc</code> works and how to use an ephemeral database for more robust type-analysis, refer to the leverage Database-backed query analysis blog post.</p> <p>Being able to validate and analyze SQL statements against a database schema greatly improves the maintainability and correctness of your application. It enables you to identify errors, like typos, missing columns, or incorrect types, during development and compile time rather than at runtime.</p>"},{"location":"blog/2024/goose-sqlc/#example","title":"Example","text":"<p>If you just want to see the code, check out mfridman/goose-demo. In that repository, you will find a simple Go application that uses <code>sqlc</code> and <code>goose</code> to interact with a SQLite database.</p> <p>You can clone the repository, and run <code>go run ./cmd/custom-goose</code>. It should print out a list of users randomly added with moby/moby namesgenerator.</p>"},{"location":"blog/2024/goose-sqlc/#pre-requisites","title":"Pre-requisites","text":"<p>Before we start, make sure you have the following installed:</p> <ul> <li>Go, version 1.20 or later</li> <li>sqlc</li> <li>goose</li> </ul>"},{"location":"blog/2024/goose-sqlc/#step-1-write-migrations","title":"Step 1 - Write migrations","text":"<p>First, we need to write the database migrations themselves. We'll dump them in a <code>./data/sql/migrations/</code> directory, but you can put them anywhere you like.</p> <p>Note, the demo repository uses a few advanced features of <code>goose</code> that are not strictly necessary, such as embedding SQL files in a binary (<code>//go:embed *.sql</code>), using Go migrations, and building up a custom <code>goose.Provider</code>.</p> <p>Alright, moving on. Here's an example of a migration file:</p> data/sql/migrations/00001_users_table.sql<pre><code>-- +goose Up\nCREATE TABLE users (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    username text NOT NULL\n);\n\n-- +goose Down\nDROP TABLE users;\n</code></pre>"},{"location":"blog/2024/goose-sqlc/#step-2-prepare-a-sqlcyaml-file","title":"Step 2 - Prepare a sqlc.yaml file","text":"<p>Next, we need to prepare a <code>sqlc.yaml</code> configuration file. It's beyond the scope of this post to explain all the options (see the sqlc documentation), but here's a minimal example:</p> sqlc.yaml<pre><code>version: \"2\"\nsql:\n  - schema: \"data/sql/migrations\" #(1)!\n    queries: \"data/sql/queries\" #(2)!\n    engine: \"sqlite\"\n    gen:\n      go:\n        out: \"gen/dbstore\"\n</code></pre> <ol> <li>The <code>schema</code> field tells <code>sqlc</code> where to look for the database schema. In this case, we're     pointing it at the same directory where we put our migrations.</li> <li>The <code>queries</code> field tells <code>sqlc</code> where to look for the SQL query files. In this case, we're     pointing it at a <code>./data/sql/queries/</code> directory.</li> </ol>"},{"location":"blog/2024/goose-sqlc/#step-3-write-sql-queries","title":"Step 3 - Write SQL queries","text":"<p>Now we can write some SQL queries that will get generated into Go code by <code>sqlc</code>. We'll dump them in a <code>./data/sql/queries/</code> directory. Here's an example of a query file:</p> <pre><code>data/sql/queries/\n\u2514\u2500\u2500 users.sql\n</code></pre> data/sql/queries/users.sql<pre><code>-- name: ListUsers :many\nSELECT * FROM users ORDER BY username;\n</code></pre> <p>Now, we're jumping ahead a bit, but let's imagine we mispelled <code>users</code> table as <code>usres</code> in the query.<code>sqlc</code> would catch this error much earlier than if we were to run the application and hit the query at runtime.</p> <pre><code>$ sqlc generate\n# package\ndata/sql/queries/users.sql:1:1: relation \"usres\" does not exist\n</code></pre>"},{"location":"blog/2024/goose-sqlc/#step-4-run-sqlc-generate","title":"Step 4 - Run <code>sqlc generate</code>","text":"<p>Now we can run <code>sqlc generate</code> to generate the Go code. This will create a <code>gen/dbstore</code> directory with the generated Go code.</p> <pre><code>$ sqlc generate\n</code></pre> <p>And that's it! We now have a <code>gen/dbstore</code> directory with the generated Go code. Here's a snippet of what the generated code looks like:</p> gen/dbstore/users.sql.go<pre><code>const listUsers = `-- name: ListUsers :many\nSELECT id, username FROM users ORDER BY username\n`\n\nfunc (q *Queries) ListUsers(ctx context.Context) ([]User, error) {\n    rows, err := q.db.QueryContext(ctx, listUsers)\n    if err != nil {\n        return nil, err\n    }\n    defer rows.Close()\n    var items []User\n    for rows.Next() {\n        var i User\n        if err := rows.Scan(&amp;i.ID, &amp;i.Username); err != nil {\n            return nil, err\n        }\n        items = append(items, i)\n    }\n    if err := rows.Close(); err != nil {\n        return nil, err\n    }\n    if err := rows.Err(); err != nil {\n        return nil, err\n    }\n    return items, nil\n}\n</code></pre> <p>Bonus, <code>sqlc</code> takes care of executing, scanning and closing the rows for you. It also takes care of error handling and returning the results.</p> <p>ps. How many times have you forgotten to close the rows?</p>"},{"location":"blog/2024/goose-sqlc/#wrapping-up","title":"Wrapping up","text":"<p>There's a lot more to <code>sqlc</code> and <code>goose</code> than what we've covered here, but hopefully this gives you a good starting point for using these tools together.</p>"},{"location":"documentation/annotations/","title":"SQL file annotations","text":"<p>Annotations are comments that are placed in SQL migration files to provide additional information to goose. They are used to parse SQL statements and optionally modify how migrations are executed.</p> <p>To summarize, annotations are:</p> <ul> <li>Case-insensitive</li> <li>Placed on their own line (no leading whitespace)</li> <li>Prefixed with <code>-- +goose</code> (<code>^--\\s\\+goose\\s.*$</code>)</li> <li>The only mandatory annotation is <code>-- +goose up</code></li> </ul> <p>There are currently seven annotations:</p> <pre><code>-- +goose up\n-- +goose down\n-- +goose statementbegin\n-- +goose statementend\n-- +goose no transaction\n-- +goose envsub on\n-- +goose envsub off\n</code></pre>"},{"location":"documentation/annotations/#quick-start","title":"Quick start","text":"<p>Here's a copy/pasteable example:</p> <pre><code>-- +goose up\nSELECT 'up SQL query';\n\n-- +goose down\nSELECT 'down SQL query';\n</code></pre> <p>Important, annotations are captured as comments and cannot have leading spaces:</p> <pre><code>-- +goose up \u2705\n\n    -- +goose up \u274c (invalid, because leading whitespace)\n</code></pre>"},{"location":"documentation/annotations/#basics","title":"Basics","text":"<p>A SQL migration file must have a .sql extension and is prefixed with either a timestamp or a sequential number. There is a handy <code>goose create</code> command to stub out migration files in a consistent way.</p> <p>Each SQL migration file is expected to have exactly one <code>-- +goose up</code> annotation.</p> <p>The <code>-- +goose down</code> annotation is optional and must come after the <code>-- +goose up</code> annotation.</p> <pre><code>-- +goose up\nSELECT 'up SQL query 1';\nSELECT 'up SQL query 2';\nSELECT 'up SQL query 3';\n\n-- +goose down (1)\nSELECT 'down SQL query 1';\nSELECT 'down SQL query 2';\n</code></pre> <ol> <li> <p>The down annotation is optional, and may be omitted entirely if there are no down migrations.     Within the <code>.sql</code> file it must come after the <code>-- +goose up</code> annotation.</p> <p>This is invalid:</p> <pre><code>-- +goose down\nSELECT 'down SQL query';\n\n-- +goose up\nSELECT 'up SQL query';\n</code></pre> </li> </ol>"},{"location":"documentation/annotations/#complex-statements","title":"Complex statements","text":"<p>By default, SQL statements are split by semicolons (<code>;</code>) and executed individually -- in fact, query statements must be separated by semicolons to be properly recognized by goose.</p> <p>More complex statements, such as PL/pgSQL functions, typically have semicolons within them and must be wrapped with <code>-- +goose statementbegin</code> and <code>-- +goose statementend</code> annotations.</p> <p>This pair of annotations tell goose to treat the entire block as a single statement. Comments, empty lines, and semicolons within the block are preserved.</p> <pre><code>-- +goose up\n\n-- +goose statementbegin\nCREATE OR REPLACE FUNCTION histories_partition_creation( DATE, DATE )\nreturns void AS $$\nDECLARE\n  create_query text;\nBEGIN\n-- This comment will be preserved.\n  -- And so will this one.\n  FOR create_query IN SELECT\n      'CREATE TABLE IF NOT EXISTS histories_'\n      || TO_CHAR( d, 'YYYY_MM' )\n      || ' ( CHECK( created_at &gt;= timestamp '''\n      || TO_CHAR( d, 'YYYY-MM-DD 00:00:00' )\n      || ''' AND created_at &lt; timestamp '''\n      || TO_CHAR( d + INTERVAL '1 month', 'YYYY-MM-DD 00:00:00' )\n      || ''' ) ) inherits ( histories );'\n    FROM generate_series( $1, $2, '1 month' ) AS d\n  LOOP\n    EXECUTE create_query;\n  END LOOP;  -- LOOP END\nEND;         -- FUNCTION END\n$$\nlanguage plpgsql;\n-- +goose statementend\n</code></pre>"},{"location":"documentation/annotations/#multiple-statements","title":"Multiple statements","text":"<p>The <code>-- +goose statementbegin</code> and <code>-- +goose statementend</code> annotations can also be used to combine multiple statements so they get sent as a single query string instead of being executed individually.</p>"},{"location":"documentation/annotations/#example","title":"Example","text":"<p>This is best illustrated with a contrived example. Suppose we have a migration that creates a users table and adds 100,000 rows with distinct INSERT's.</p> <pre><code>-- +goose up\nCREATE TABLE users (\n    id int NOT NULL PRIMARY KEY,\n    username text\n);\n\n-- (1)! Inserts:\nINSERT INTO \"users\" (\"id\", \"name\") VALUES (1, 'gallant_almeida7');\nINSERT INTO \"users\" (\"id\", \"name\") VALUES (2, 'brave_spence8');\n.\n.\nINSERT INTO \"users\" (\"id\", \"name\") VALUES (99999, 'jovial_chaum1');\nINSERT INTO \"users\" (\"id\", \"name\") VALUES (100000, 'goofy_ptolemy0');\n\n-- +goose down\nDROP TABLE users;\n</code></pre> <ol> <li> <p>This is a contrived example. Normally this would be a set of batched <code>INSERT</code>'s with multiple     column values, each enclosed with parentheses and separated by commas, like so:</p> <pre><code>INSERT INTO \"users\" (\"id\", \"username\")\nVALUES\n  (1, 'gallant_almeida7'),\n  (2, 'brave_spence8');\n</code></pre> </li> </ol> <p>The up migration contains 100,001 unique statements, all executed within the same transaction, but sent to the database one-by-one. This migration will take ~30s to complete due to the number of round trips.</p> <p>Using PostgreSQL as an example, here's what the database logs show:</p> <pre><code>LOG:  statement: INSERT INTO \"users\" (\"id\", \"username\") VALUES (1, 'gallant_almeida7');\nLOG:  statement: INSERT INTO \"users\" (\"id\", \"username\") VALUES (2, 'brave_spence8');\nLOG:  statement: INSERT INTO \"users\" (\"id\", \"username\") VALUES (3, 'lucid_bardeen6');\n[...] 100,000 log statements\n</code></pre> <p>However, if we wrap the inserts with <code>-- +goose statementbegin</code> and <code>-- +goose statementend</code> annotations, the entire block will be sent to the server as a single command.</p> <p>A single command still contains several statements separated by semicolons, but they get sent to the server in the same query string: <code>\"INSERT INTO ...; INSERT INTO ...;\"</code>.</p> <pre><code>-- +goose up\nCREATE TABLE users (\n    id int NOT NULL PRIMARY KEY,\n    username text,\n    name text,\n    surname text\n);\n\n-- +goose statementbegin\nINSERT INTO \"users\" (\"id\", \"username\") VALUES (1, 'gallant_almeida7');\nINSERT INTO \"users\" (\"id\", \"username\") VALUES (2, 'brave_spence8');\n.\n.\nINSERT INTO \"users\" (\"id\", \"username\") VALUES (99999, 'jovial_chaum1');\nINSERT INTO \"users\" (\"id\", \"username\") VALUES (100000, 'goofy_ptolemy0');\n-- +goose statementend\n\n-- +goose down\nDROP TABLE users;\n</code></pre> <p>These annotations instruct goose to execute the entire block as a single statement. Yes, that's a larger payload, but that's fine and the migration will execute in ~3s, which is an order of magnitude faster as compared to the previous example that ran in ~30s.</p>"},{"location":"documentation/annotations/#no-transaction","title":"No transaction","text":"<p>All statements within a single migration file are run within the same transaction. However, some statements, like <code>CREATE DATABASE</code> or <code>CREATE INDEX CONCURRENTLY</code>, cannot be run within a transaction block.</p> <p>For such cases add the <code>-- +goose no transaction</code> annotation, usually placed at the top of the file.</p> <p>This annotation instructs goose to run all statements within the file outside a transaction. This applies to all up and down statements within the file.</p> <pre><code>-- +goose no transaction\n\n-- +goose up\nCREATE INDEX CONCURRENTLY ON users (user_id);\n\n-- +goose down\nDROP INDEX users_user_id_idx;\n</code></pre>"},{"location":"documentation/annotations/#environment-variable-substitution","title":"Environment variable substitution","text":"<p>Goose supports environment variable substitution in SQL migration files. This is useful for parameterizing SQL queries with values that are not known at the time of writing the migration.</p> <p>Substitution is disabled by default. To enable it, add the <code>-- +goose envsub on</code> annotation at the location where you want to start substituting environment variables. This could be at the top of the file, which enables substitution for the entire file, or at a specific location within the file.</p> <p>goose will attempt to substitute environment variables until the end of the file, or until the annotation <code>-- +goose envsub off</code> is found.</p> <p>For example, if the environment variable <code>REGION</code> is set to <code>us_east_1</code>, the following SQL migration will be substituted to <code>SELECT * FROM regions WHERE name = 'us_east_1';</code>.</p> <pre><code>-- +goose envsub on\n\n-- +goose up\nSELECT * FROM regions WHERE name = '${REGION}';\n</code></pre>"},{"location":"documentation/annotations/#supported-expansions","title":"Supported expansions","text":"<ul> <li><code>${parameter}</code> or <code>$parameter</code></li> <li><code>${parameter:-[word]}</code></li> <li><code>${parameter-[word]}</code></li> <li><code>${parameter:[offset]}</code></li> <li><code>${parameter:[offset]:[length]}</code></li> <li><code>${parameter?[word]}</code></li> <li><code>${parameter:?[word]}</code> (coming soon)</li> </ul> <p>For an explanation of each expansion, refer to the mfridman/interpolate package. In due time, we'll update the documentation to reflect the supported expansions.</p>"},{"location":"documentation/cli-commands/","title":"Commands","text":"<p>The following commands are part of the stable set of commands and will remain backwards compatible across minor/patch upgrades.</p> <pre><code>Usage: goose [flags] DRIVER DBSTRING &lt;command&gt;\n</code></pre> <p>Flags must come before commands, otherwise they will be interpreted as arguments to the command.</p> <p>Both <code>DRIVER</code> and <code>DBSTRING</code> may be set using environment variables <code>GOOSE_DRIVER</code> and <code>GOOSE_DBSTRING</code>. See the environment variables documentation for more information.</p>"},{"location":"documentation/cli-commands/#commands_1","title":"Commands","text":""},{"location":"documentation/cli-commands/#up","title":"<code>up</code>","text":"<p>Migrate the DB to the most recent version available</p>"},{"location":"documentation/cli-commands/#up-by-one","title":"up-by-one","text":"<p>Migrate the DB up by 1</p>"},{"location":"documentation/cli-commands/#up-to","title":"up-to","text":"<p>Migrate the DB to a specific VERSION</p>"},{"location":"documentation/cli-commands/#down","title":"down","text":"<p>Roll back the version by 1</p>"},{"location":"documentation/cli-commands/#down-to","title":"down-to","text":"<p>Roll back to a specific VERSION</p>"},{"location":"documentation/cli-commands/#redo","title":"redo","text":"<p>Re-run the latest migration</p>"},{"location":"documentation/cli-commands/#reset","title":"reset","text":"<p>Roll back all migrations</p>"},{"location":"documentation/cli-commands/#status","title":"status","text":"<p>Dump the migration status for the current DB</p>"},{"location":"documentation/cli-commands/#version","title":"version","text":"<p>Print the current version of the database</p>"},{"location":"documentation/cli-commands/#create","title":"create","text":"<p>Creates new migration file with the current timestamp</p>"},{"location":"documentation/cli-commands/#fix","title":"fix","text":"<p>Apply sequential ordering to migrations</p>"},{"location":"documentation/cli-commands/#supported-drivers","title":"Supported Drivers","text":"Driver Go package <code>clickhouse</code> <code>github.com/ClickHouse/clickhouse-go/v2</code> <code>mssql</code> <code>github.com/microsoft/go-mssqldb</code> <code>mysql</code> <code>github.com/go-sql-driver/mysql</code> <code>postgres</code> <code>github.com/jackc/pgx/v5/stdlib</code> <code>sqlite3</code> <code>modernc.org/sqlite</code> <code>turso</code> <code>github.com/tursodatabase/libsql-client-go/libsql</code> <code>vertica</code> <code>github.com/vertica/vertica-sql-go</code> <code>ydb</code> <code>github.com/yandex-cloud/ydb-go-sdk/v2</code>"},{"location":"documentation/custom-store/","title":"Custom store","text":"<p>Goose aims to support a large number of dialects out-of-the-box, but it's either not possible or nor practical to support every database. In these cases, users can bring their own store implementation assuming it fits the <code>database.Store</code> interface.</p> <p>The core goose library leverages a <code>database.Store</code> interface to interact with the database, but it makes no assumptions about the underlying database.</p>"},{"location":"documentation/custom-store/#usage","title":"Usage","text":"<p>To use a custom store, simply pass it to the Provider when creating a new instance by supplying the <code>goose.WithStore</code> option.</p> <pre><code>provider, err := goose.NewProvider(\n    \"\",\n    db,\n    migrations.Embed,\n    // Use custom store implementation.\n    goose.WithStore(memory.New(\"goose_migrations\")),\n)\nif err != nil {\n    return err\n}\n</code></pre> <p>Note</p> <p>When using a custom store, the first argument to <code>goose.NewProvider</code> must be an empty string.</p>"},{"location":"documentation/custom-store/#store-interface","title":"Store interface","text":"<p>More documentation on the <code>database.Store</code> interface can be found in the godoc, but here is a brief overview:</p> <pre><code>type Store interface {\n    // Tablename is the name of the version table. This table is used to record applied migrations\n    // and must not be an empty string.\n    Tablename() string\n\n    // CreateVersionTable creates the version table, which is used to track migrations. When\n    // creating this table, the implementation MUST also insert a row for the initial version (0).\n    CreateVersionTable(ctx context.Context, db DBTxConn) error\n\n    // Insert a version id into the version table.\n    Insert(ctx context.Context, db DBTxConn, req InsertRequest) error\n\n    // Delete a version id from the version table.\n    Delete(ctx context.Context, db DBTxConn, version int64) error\n\n    // GetMigration retrieves a single migration by version id. If the query succeeds, but the\n    // version is not found, this method must return [ErrVersionNotFound].\n    GetMigration(ctx context.Context, db DBTxConn, version int64) (*GetMigrationResult, error)\n\n    // GetLatestVersion retrieves the last applied migration version. If no migrations exist, this\n    // method must return [ErrVersionNotFound].\n    GetLatestVersion(ctx context.Context, db DBTxConn) (int64, error)\n\n    // ListMigrations retrieves all migrations sorted in descending order by id or timestamp. If\n    // there are no migrations, return empty slice with no error. Typically this method will return\n    // at least one migration, because the initial version (0) is always inserted into the version\n    // table when it is created.\n    ListMigrations(ctx context.Context, db DBTxConn) ([]*ListMigrationsResult, error)\n}\n</code></pre>"},{"location":"documentation/custom-store/#example","title":"Example","text":"<p>Although a bit of a contrived example, see this memory store for a reference implementation.</p>"},{"location":"documentation/environment-variables/","title":"Environment variables","text":"<p>Goose supports environment variables that can be used instead of command line arguments or flags. This is useful for setting defaults or for use in automation scripts.</p> <p>Environment variables have lower precedence than command line arguments and flags.</p> <p>The following environment variables are supported:</p> <ul> <li><code>GOOSE_DRIVER</code> - The database driver to use</li> <li><code>GOOSE_DBSTRING</code> - The database connection string</li> <li><code>GOOSE_MIGRATION_DIR</code> - The directory containing the migration files (default: <code>.</code>)</li> <li><code>NO_COLOR</code> - Disable color output</li> </ul>"},{"location":"documentation/provider/","title":"Goose provider","text":"<p>The Provider type is the entry point for the goose library. It initializes the state and provides methods to run migrations. It does not have global state, so you can create multiple providers with different configurations.</p> <p>Initialize a provider by calling <code>goose.NewProvider()</code>:</p> <pre><code>func NewProvider(\n    dialect Dialect,\n    db *sql.DB,\n    fsys fs.FS,\n    opts ...ProviderOption,\n) (*Provider, error){\n    // ...\n}\n</code></pre>"},{"location":"documentation/provider/#provider","title":"Provider","text":""},{"location":"documentation/provider/#dialect","title":"Dialect","text":"<p>The <code>Dialect</code> defines the SQL dialect of the database. Simply put, goose needs to know the raw SQL syntax of the database its working with.</p> <p>Each dialect has a corresponding constant backed by a database.Store implementation.</p> <p>For most users its sufficient to use one of the natively supported dialects and not worry about the database store. For more advanced users, you may bring your own dialect and store, see the TODO section for more information.</p>"},{"location":"documentation/provider/#db","title":"db","text":"<p>The <code>*sql.DB</code> is the database connection that goose will use to run migrations. Goose intentionally does not care which database driver is used.</p> <p>The caller is responsible for matching the dialect with the database driver. For example, if you are using the <code>goose.DialectPostgres</code> dialect, you'd pick the jackc/pgx driver.</p>"},{"location":"documentation/provider/#fsys","title":"fsys","text":"<p>The <code>fs.FS</code> is the filesystem abstraction that goose will use to read migration files. This is will typically be <code>os.DirFS</code>, <code>embed.FS</code>.</p> <p>Quite often you may have a heirarchy of directories with migrations, in which case you can use <code>fs.Sub</code> to create a sub filesystem.</p> <pre><code>fsys, err := fs.Sub(embeddedFS, \"migrations\")\n</code></pre> <p>And then pass the <code>fsys</code> to the provider.</p>"},{"location":"documentation/provider/#provider-options","title":"Provider Options","text":"<p>The <code>ProviderOption</code> is a functional option type that allows you to configure and customize the provider.</p>"},{"location":"documentation/provider/#withstore","title":"WithStore","text":""},{"location":"documentation/provider/#withverbose","title":"WithVerbose","text":"<pre><code>func WithVerbose(b bool)\n</code></pre> <p>This option enables verbose logging of the migration process. For example, here's the output of running an up migration with verbose logging:</p> <pre><code>goose: OK    up 00001_users_table.sql (1.32ms)\ngoose: OK    up 00002_add_users.go (638.96\u00b5s)\ngoose: OK    up 00003_count_users.go (561.58\u00b5s)\ngoose: successfully migrated database, current version: 3\n</code></pre> <p>By default, the provider methods do not log anything by default.</p>"},{"location":"documentation/provider/#withsessionlocker","title":"WithSessionLocker","text":"<pre><code>func WithSessionLocker(locker lock.SessionLocker)\n</code></pre> <p>By default, goose does not lock the database during migrations. It is up to the caller to ensure migrations are run in a safe manner. Which means in certain environments, such as Kubernetes, you may have multiple instances of your application running migrations concurrently.</p> <p>By configuring a <code>SessionLocker</code>, you can ensure that only one instance of your application runs migrations at a time.</p> <p>The lock package provides a few implementations of the <code>SessionLocker</code> interface:</p>"},{"location":"documentation/provider/#postgres","title":"Postgres","text":"<p>The <code>NewPostgresSessionLocker</code> function creates a <code>SessionLocker</code> that can be used to acquire and release a lock for synchronization purposes. The lock acquisition is retried until it is successfully acquired or until the failure threshold is reached.</p> <p>The default lock duration is set to 5 minutes, and the default unlock duration is set to 1 minute. These can be tuned.</p>"},{"location":"documentation/provider/#withexcludenames","title":"WithExcludeNames","text":"<pre><code>func WithExcludeNames(excludes []string)\n</code></pre> <p>The option excludes the given file names from the list of migrations. If called multiple times, the list of excludes is merged.</p>"},{"location":"documentation/provider/#withexcludeversions","title":"WithExcludeVersions","text":"<pre><code>func WithExcludeVersions(versions []int64)\n</code></pre> <p>This option excludes the given versions from the list of migrations. If called multiple times, the list of excludes is merged.</p>"},{"location":"documentation/provider/#withgomigrations","title":"WithGoMigrations","text":"<pre><code>func WithGoMigrations(migrations ...*Migration)\n</code></pre> <p>This option adds the given Go migration to the list of migrations. The migration must be constructed using the <code>NewGoMigration</code> constructor.</p>"},{"location":"documentation/provider/#newgomigration","title":"NewGoMigration","text":"<pre><code>func NewGoMigration(version int64, up, down *GoFunc) *Migration\n</code></pre> <p>This function creates a new Go migration, which may be registered with a provider or globally.</p> <p>Both up and down functions may be <code>nil</code>, in which case the migration will be recorded in the versions table but no functions will be run. This is useful for recording (up) or deleting (down) a version without running any functions.</p> <p>A Go migration can either be executed within or outside a transaction and only one can be set. If both are set, an error will be returned.</p> <pre><code>RunTx func(ctx context.Context, tx *sql.Tx) error\n\n// or\n\nRunDB func(ctx context.Context, db *sql.DB) error\n</code></pre>"},{"location":"documentation/provider/#withdisableglobalregistry","title":"WithDisableGlobalRegistry","text":"<pre><code>func WithDisableGlobalRegistry(b bool)\n</code></pre> <p>This option disables the global registry. By default, goose uses a global registry to store all migrations. This is useful for running migrations in a single process. If you are running migrations in multiple processes, you should disable the global registry and register migrations with the provider.</p>"},{"location":"documentation/provider/#withallowoutoforder","title":"WithAllowOutofOrder","text":"<pre><code>func WithAllowOutofOrder(b bool)\n</code></pre> <p>This option allows migrations to be run out-of-order, this is often called \"allow missing\" migrations. By default, goose will error if it detects that a migration is missing.</p> <p>For example: migrations 1,3 are applied to the database and then versions 2,6 are introduced. If this option is true, then goose will apply 2 (missing) and 6 (new) instead of raising an error.</p> <p>The final order of applied migrations will be: 1,3,2,6. Out-of-order migrations are always applied first, followed by new migrations.</p>"},{"location":"documentation/provider/#withdisableversioning","title":"WithDisableVersioning","text":"<pre><code>func WithDisableVersioning(b bool)\n</code></pre> <p>This option disables versioning. Disabling versioning allows applying migrations without tracking the versions in the database schema table. Useful for tests, seeding a database or running ad-hoc queries. By default, goose will track all versions in the database schema table.</p>"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/archive/2022/","title":"2022","text":""},{"location":"blog/archive/2021/","title":"2021","text":""},{"location":"blog/category/blog/","title":"Blog","text":""},{"location":"blog/category/package/","title":"Package","text":""},{"location":"blog/category/sql-migrations/","title":"SQL migrations","text":""},{"location":"blog/category/clickhouse/","title":"ClickHouse","text":""},{"location":"blog/category/general/","title":"General","text":""},{"location":"blog/category/testing/","title":"Testing","text":""},{"location":"blog/category/go-migrations/","title":"Go migrations","text":""}]}